{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLGlot Explainer: Snowflake to BigQuery Transpilation\n",
    "\n",
    "This notebook demonstrates how to use SQLGlot to transpile SQL queries from Snowflake syntax to BigQuery syntax.\n",
    "\n",
    "## Overview\n",
    "\n",
    "SQLGlot is a no-dependency SQL parser, transpiler, and optimizer. It can parse SQL queries from various dialects, convert them to different SQL dialects, and optimize them.\n",
    "\n",
    "### Key Features:\n",
    "- Parse SQL from one dialect (e.g., Snowflake)\n",
    "- Transpile to another dialect (e.g., BigQuery)\n",
    "- Handle syntax differences automatically\n",
    "- Preserve query semantics\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Basic transpilation between Snowflake and BigQuery\n",
    "2. Common syntax differences between the two dialects\n",
    "3. Handling complex queries (JOINs, window functions, etc.)\n",
    "4. Identifying edge cases and manual adjustments needed\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This notebook does NOT connect to any databases. We're only working with SQL strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLGlot version: 28.6.0\n"
     ]
    }
   ],
   "source": [
    "# Install/import required libraries\n",
    "import sqlglot\n",
    "from sqlglot import exp, parse_one, transpile\n",
    "from sqlglot.dialects import Snowflake, BigQuery\n",
    "from pprint import pprint\n",
    "\n",
    "print(f\"SQLGlot version: {sqlglot.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Transpilation\n",
    "\n",
    "Let's start with a simple SELECT query and see how SQLGlot converts it from Snowflake to BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE SQL:\n",
      "================================================================================\n",
      "\n",
      "SELECT \n",
      "    id,\n",
      "    name,\n",
      "    email\n",
      "FROM users\n",
      "WHERE active = TRUE\n",
      "LIMIT 100\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY SQL:\n",
      "================================================================================\n",
      "SELECT\n",
      "  id,\n",
      "  name,\n",
      "  email\n",
      "FROM users\n",
      "WHERE\n",
      "  active = TRUE\n",
      "LIMIT 100\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Simple SELECT query\n",
    "snowflake_sql = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    name,\n",
    "    email\n",
    "FROM users\n",
    "WHERE active = TRUE\n",
    "LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_sql)\n",
    "\n",
    "# Transpile from Snowflake to BigQuery\n",
    "bigquery_sql = transpile(\n",
    "    snowflake_sql,\n",
    "    read=Snowflake,\n",
    "    write=BigQuery,\n",
    "    pretty=True\n",
    ")[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BIGQUERY SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(bigquery_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Type Differences\n",
    "\n",
    "Snowflake and BigQuery have different data type names. SQLGlot handles most conversions automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE CREATE TABLE:\n",
      "================================================================================\n",
      "\n",
      "CREATE TABLE products (\n",
      "    id NUMBER(38, 0),\n",
      "    name VARCHAR(255),\n",
      "    price DECIMAL(10, 2),\n",
      "    description TEXT,\n",
      "    created_at TIMESTAMP_NTZ,\n",
      "    metadata VARIANT\n",
      ")\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY CREATE TABLE:\n",
      "================================================================================\n",
      "CREATE TABLE products (\n",
      "  id NUMERIC(38, 0),\n",
      "  name STRING(255),\n",
      "  price NUMERIC(10, 2),\n",
      "  description STRING,\n",
      "  created_at DATETIME,\n",
      "  metadata ANY TYPE\n",
      ")\n",
      "\n",
      "================================================================================\n",
      "KEY DIFFERENCES NOTED:\n",
      "================================================================================\n",
      "â€¢ NUMBER â†’ INT64 or NUMERIC (depending on precision)\n",
      "â€¢ VARCHAR â†’ STRING\n",
      "â€¢ TEXT â†’ STRING\n",
      "â€¢ TIMESTAMP_NTZ â†’ TIMESTAMP\n",
      "â€¢ VARIANT â†’ JSON (BigQuery uses JSON type)\n"
     ]
    }
   ],
   "source": [
    "# Example 2: CREATE TABLE with data types\n",
    "snowflake_create_table = \"\"\"\n",
    "CREATE TABLE products (\n",
    "    id NUMBER(38, 0),\n",
    "    name VARCHAR(255),\n",
    "    price DECIMAL(10, 2),\n",
    "    description TEXT,\n",
    "    created_at TIMESTAMP_NTZ,\n",
    "    metadata VARIANT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE CREATE TABLE:\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_create_table)\n",
    "\n",
    "bigquery_create_table = transpile(\n",
    "    snowflake_create_table,\n",
    "    read=Snowflake,\n",
    "    write=BigQuery,\n",
    "    pretty=True\n",
    ")[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BIGQUERY CREATE TABLE:\")\n",
    "print(\"=\" * 80)\n",
    "print(bigquery_create_table)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY DIFFERENCES NOTED:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"â€¢ NUMBER â†’ INT64 or NUMERIC (depending on precision)\")\n",
    "print(\"â€¢ VARCHAR â†’ STRING\")\n",
    "print(\"â€¢ TEXT â†’ STRING\")\n",
    "print(\"â€¢ TIMESTAMP_NTZ â†’ TIMESTAMP\")\n",
    "print(\"â€¢ VARIANT â†’ JSON (BigQuery uses JSON type)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. String Functions and Concatenation\n",
    "\n",
    "Snowflake uses `||` for string concatenation (like Oracle), while BigQuery uses `CONCAT()` function. SQLGlot handles this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE SQL (using || operator):\n",
      "================================================================================\n",
      "\n",
      "SELECT \n",
      "    first_name || ' ' || last_name AS full_name,\n",
      "    email || '@company.com' AS company_email\n",
      "FROM users\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY SQL (using CONCAT function):\n",
      "================================================================================\n",
      "SELECT\n",
      "  first_name || ' ' || last_name AS full_name,\n",
      "  email || '@company.com' AS company_email\n",
      "FROM users\n"
     ]
    }
   ],
   "source": [
    "# Example 3: String concatenation\n",
    "snowflake_concat = \"\"\"\n",
    "SELECT \n",
    "    first_name || ' ' || last_name AS full_name,\n",
    "    email || '@company.com' AS company_email\n",
    "FROM users\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE SQL (using || operator):\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_concat)\n",
    "\n",
    "bigquery_concat = transpile(\n",
    "    snowflake_concat,\n",
    "    read=Snowflake,\n",
    "    write=BigQuery,\n",
    "    pretty=True\n",
    ")[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BIGQUERY SQL (using CONCAT function):\")\n",
    "print(\"=\" * 80)\n",
    "print(bigquery_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Date and Time Functions\n",
    "\n",
    "Date functions differ between Snowflake and BigQuery. Let's examine some common date operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE SQL:\n",
      "================================================================================\n",
      "\n",
      "SELECT \n",
      "    CURRENT_DATE() AS today,\n",
      "    DATEADD(day, -7, CURRENT_DATE()) AS last_week,\n",
      "    DATEDIFF(day, created_at, CURRENT_DATE()) AS days_ago,\n",
      "    DATE_TRUNC('month', created_at) AS month_start,\n",
      "    EXTRACT(YEAR FROM created_at) AS year\n",
      "FROM orders\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY SQL:\n",
      "================================================================================\n",
      "SELECT\n",
      "  CURRENT_DATE AS today,\n",
      "  DATE_ADD(CURRENT_DATE, INTERVAL -7 DAY) AS last_week,\n",
      "  DATE_DIFF(CURRENT_DATE, created_at, DAY) AS days_ago,\n",
      "  TIMESTAMP_TRUNC(created_at, MONTH) AS month_start,\n",
      "  EXTRACT(YEAR FROM created_at) AS year\n",
      "FROM orders\n",
      "\n",
      "================================================================================\n",
      "FUNCTION MAPPINGS:\n",
      "================================================================================\n",
      "â€¢ DATEADD(day, -7, date) â†’ DATE_SUB(date, INTERVAL 7 DAY)\n",
      "â€¢ DATEDIFF(day, date1, date2) â†’ DATE_DIFF(date2, date1, DAY)\n",
      "â€¢ DATE_TRUNC('month', date) â†’ DATE_TRUNC(date, MONTH)\n",
      "â€¢ EXTRACT(YEAR FROM date) â†’ EXTRACT(YEAR FROM date) (same)\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Date functions\n",
    "snowflake_date = \"\"\"\n",
    "SELECT \n",
    "    CURRENT_DATE() AS today,\n",
    "    DATEADD(day, -7, CURRENT_DATE()) AS last_week,\n",
    "    DATEDIFF(day, created_at, CURRENT_DATE()) AS days_ago,\n",
    "    DATE_TRUNC('month', created_at) AS month_start,\n",
    "    EXTRACT(YEAR FROM created_at) AS year\n",
    "FROM orders\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_date)\n",
    "\n",
    "bigquery_date = transpile(\n",
    "    snowflake_date,\n",
    "    read=Snowflake,\n",
    "    write=BigQuery,\n",
    "    pretty=True\n",
    ")[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BIGQUERY SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(bigquery_date)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FUNCTION MAPPINGS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"â€¢ DATEADD(day, -7, date) â†’ DATE_SUB(date, INTERVAL 7 DAY)\")\n",
    "print(\"â€¢ DATEDIFF(day, date1, date2) â†’ DATE_DIFF(date2, date1, DAY)\")\n",
    "print(\"â€¢ DATE_TRUNC('month', date) â†’ DATE_TRUNC(date, MONTH)\")\n",
    "print(\"â€¢ EXTRACT(YEAR FROM date) â†’ EXTRACT(YEAR FROM date) (same)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Window Functions\n",
    "\n",
    "Window functions work similarly in both dialects, but there might be subtle differences in syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'NULLS LAST' translation not supported in window functions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE SQL:\n",
      "================================================================================\n",
      "\n",
      "SELECT \n",
      "    id,\n",
      "    user_id,\n",
      "    amount,\n",
      "    ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n",
      "    SUM(amount) OVER (PARTITION BY user_id) AS user_total,\n",
      "    AVG(amount) OVER (ORDER BY created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg\n",
      "FROM orders\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY SQL:\n",
      "================================================================================\n",
      "SELECT\n",
      "  id,\n",
      "  user_id,\n",
      "  amount,\n",
      "  ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC NULLS FIRST) AS rn,\n",
      "  SUM(amount) OVER (PARTITION BY user_id) AS user_total,\n",
      "  AVG(amount) OVER (ORDER BY created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg\n",
      "FROM orders\n",
      "\n",
      "================================================================================\n",
      "NOTE:\n",
      "================================================================================\n",
      "Window functions are generally compatible between Snowflake and BigQuery.\n",
      "SQLGlot preserves the window function syntax where it's the same.\n"
     ]
    }
   ],
   "source": [
    "# Example 5: Window functions\n",
    "snowflake_window = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    user_id,\n",
    "    amount,\n",
    "    ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at DESC) AS rn,\n",
    "    SUM(amount) OVER (PARTITION BY user_id) AS user_total,\n",
    "    AVG(amount) OVER (ORDER BY created_at ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS rolling_avg\n",
    "FROM orders\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_window)\n",
    "\n",
    "bigquery_window = transpile(\n",
    "    snowflake_window,\n",
    "    read=Snowflake,\n",
    "    write=BigQuery,\n",
    "    pretty=True\n",
    ")[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BIGQUERY SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(bigquery_window)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NOTE:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Window functions are generally compatible between Snowflake and BigQuery.\")\n",
    "print(\"SQLGlot preserves the window function syntax where it's the same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. JOINs and Table Aliases\n",
    "\n",
    "JOIN syntax is largely compatible, but table qualifiers and identifiers might need adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE SQL:\n",
      "================================================================================\n",
      "\n",
      "SELECT \n",
      "    o.order_id,\n",
      "    o.amount,\n",
      "    u.email,\n",
      "    p.product_name\n",
      "FROM orders o\n",
      "INNER JOIN users u ON o.user_id = u.id\n",
      "LEFT JOIN order_items oi ON o.order_id = oi.order_id\n",
      "LEFT JOIN products p ON oi.product_id = p.id\n",
      "WHERE o.created_at >= '2024-01-01'\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY SQL:\n",
      "================================================================================\n",
      "SELECT\n",
      "  o.order_id,\n",
      "  o.amount,\n",
      "  u.email,\n",
      "  p.product_name\n",
      "FROM orders AS o\n",
      "INNER JOIN users AS u\n",
      "  ON o.user_id = u.id\n",
      "LEFT JOIN order_items AS oi\n",
      "  ON o.order_id = oi.order_id\n",
      "LEFT JOIN products AS p\n",
      "  ON oi.product_id = p.id\n",
      "WHERE\n",
      "  o.created_at >= '2024-01-01'\n"
     ]
    }
   ],
   "source": [
    "# Example 6: JOINs with table aliases\n",
    "snowflake_join = \"\"\"\n",
    "SELECT \n",
    "    o.order_id,\n",
    "    o.amount,\n",
    "    u.email,\n",
    "    p.product_name\n",
    "FROM orders o\n",
    "INNER JOIN users u ON o.user_id = u.id\n",
    "LEFT JOIN order_items oi ON o.order_id = oi.order_id\n",
    "LEFT JOIN products p ON oi.product_id = p.id\n",
    "WHERE o.created_at >= '2024-01-01'\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_join)\n",
    "\n",
    "bigquery_join = transpile(\n",
    "    snowflake_join,\n",
    "    read=Snowflake,\n",
    "    write=BigQuery,\n",
    "    pretty=True\n",
    ")[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BIGQUERY SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(bigquery_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Array and JSON Functions\n",
    "\n",
    "Snowflake and BigQuery handle arrays and JSON differently. SQLGlot attempts to map these appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE SQL:\n",
      "================================================================================\n",
      "\n",
      "SELECT \n",
      "    id,\n",
      "    ARRAY_SIZE(tags) AS tag_count,\n",
      "    tags[0] AS first_tag,\n",
      "    OBJECT_KEYS(metadata) AS metadata_keys,\n",
      "    GET(metadata, 'status') AS status\n",
      "FROM products\n",
      "WHERE ARRAY_CONTAINS(tags, 'featured') = TRUE\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY SQL:\n",
      "================================================================================\n",
      "SELECT\n",
      "  id,\n",
      "  ARRAY_LENGTH(tags) AS tag_count,\n",
      "  tags[0] AS first_tag,\n",
      "  JSON_KEYS(metadata) AS metadata_keys,\n",
      "  JSON_EXTRACT(metadata, '$.status') AS status\n",
      "FROM products\n",
      "WHERE\n",
      "  EXISTS(\n",
      "    SELECT\n",
      "      1\n",
      "    FROM UNNEST('featured') AS _col\n",
      "    WHERE\n",
      "      _col = tags\n",
      "  ) = TRUE\n"
     ]
    }
   ],
   "source": [
    "# Example 7: Array and JSON operations\n",
    "snowflake_array_json = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    ARRAY_SIZE(tags) AS tag_count,\n",
    "    tags[0] AS first_tag,\n",
    "    OBJECT_KEYS(metadata) AS metadata_keys,\n",
    "    GET(metadata, 'status') AS status\n",
    "FROM products\n",
    "WHERE ARRAY_CONTAINS(tags, 'featured') = TRUE\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_array_json)\n",
    "\n",
    "try:\n",
    "    bigquery_array_json = transpile(\n",
    "        snowflake_array_json,\n",
    "        read=Snowflake,\n",
    "        write=BigQuery,\n",
    "        pretty=True\n",
    "    )[0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"BIGQUERY SQL:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(bigquery_array_json)\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸  TRANSPILATION ISSUE:\")\n",
    "    print(f\"   {e}\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MANUAL CONVERSION NEEDED:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"â€¢ ARRAY_SIZE() â†’ ARRAY_LENGTH() in BigQuery\")\n",
    "    print(\"â€¢ tags[0] â†’ tags[OFFSET(0)] in BigQuery\")\n",
    "    print(\"â€¢ OBJECT_KEYS() â†’ JSON_EXTRACT_SCALAR() + different approach\")\n",
    "    print(\"â€¢ GET() â†’ JSON_EXTRACT_SCALAR() in BigQuery\")\n",
    "    print(\"â€¢ ARRAY_CONTAINS() â†’ 'value' IN UNNEST(tags) in BigQuery\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. CTEs (Common Table Expressions)\n",
    "\n",
    "CTEs work similarly in both dialects, but let's verify the transpilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE SQL:\n",
      "================================================================================\n",
      "\n",
      "WITH active_users AS (\n",
      "    SELECT id, email, created_at\n",
      "    FROM users\n",
      "    WHERE active = TRUE\n",
      "),\n",
      "recent_orders AS (\n",
      "    SELECT user_id, SUM(amount) AS total_amount\n",
      "    FROM orders\n",
      "    WHERE created_at >= DATEADD(day, -30, CURRENT_DATE())\n",
      "    GROUP BY user_id\n",
      ")\n",
      "SELECT \n",
      "    u.id,\n",
      "    u.email,\n",
      "    COALESCE(o.total_amount, 0) AS order_total\n",
      "FROM active_users u\n",
      "LEFT JOIN recent_orders o ON u.id = o.user_id\n",
      "ORDER BY order_total DESC\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY SQL:\n",
      "================================================================================\n",
      "WITH active_users AS (\n",
      "  SELECT\n",
      "    id,\n",
      "    email,\n",
      "    created_at\n",
      "  FROM users\n",
      "  WHERE\n",
      "    active = TRUE\n",
      "), recent_orders AS (\n",
      "  SELECT\n",
      "    user_id,\n",
      "    SUM(amount) AS total_amount\n",
      "  FROM orders\n",
      "  WHERE\n",
      "    created_at >= DATE_ADD(CURRENT_DATE, INTERVAL -30 DAY)\n",
      "  GROUP BY\n",
      "    user_id\n",
      ")\n",
      "SELECT\n",
      "  u.id,\n",
      "  u.email,\n",
      "  COALESCE(o.total_amount, 0) AS order_total\n",
      "FROM active_users AS u\n",
      "LEFT JOIN recent_orders AS o\n",
      "  ON u.id = o.user_id\n",
      "ORDER BY\n",
      "  order_total DESC NULLS FIRST\n"
     ]
    }
   ],
   "source": [
    "# Example 8: CTEs (Common Table Expressions)\n",
    "snowflake_cte = \"\"\"\n",
    "WITH active_users AS (\n",
    "    SELECT id, email, created_at\n",
    "    FROM users\n",
    "    WHERE active = TRUE\n",
    "),\n",
    "recent_orders AS (\n",
    "    SELECT user_id, SUM(amount) AS total_amount\n",
    "    FROM orders\n",
    "    WHERE created_at >= DATEADD(day, -30, CURRENT_DATE())\n",
    "    GROUP BY user_id\n",
    ")\n",
    "SELECT \n",
    "    u.id,\n",
    "    u.email,\n",
    "    COALESCE(o.total_amount, 0) AS order_total\n",
    "FROM active_users u\n",
    "LEFT JOIN recent_orders o ON u.id = o.user_id\n",
    "ORDER BY order_total DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_cte)\n",
    "\n",
    "bigquery_cte = transpile(\n",
    "    snowflake_cte,\n",
    "    read=Snowflake,\n",
    "    write=BigQuery,\n",
    "    pretty=True\n",
    ")[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BIGQUERY SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(bigquery_cte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conditional Logic: CASE and IF Functions\n",
    "\n",
    "Both dialects support CASE statements, but function-based conditionals differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE SQL:\n",
      "================================================================================\n",
      "\n",
      "SELECT \n",
      "    id,\n",
      "    CASE \n",
      "        WHEN amount > 1000 THEN 'high'\n",
      "        WHEN amount > 100 THEN 'medium'\n",
      "        ELSE 'low'\n",
      "    END AS order_tier,\n",
      "    IFF(status = 'completed', amount, 0) AS completed_amount,\n",
      "    NULLIF(description, '') AS description_or_null\n",
      "FROM orders\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY SQL:\n",
      "================================================================================\n",
      "SELECT\n",
      "  id,\n",
      "  CASE WHEN amount > 1000 THEN 'high' WHEN amount > 100 THEN 'medium' ELSE 'low' END AS order_tier,\n",
      "  IF(status = 'completed', amount, 0) AS completed_amount,\n",
      "  NULLIF(description, '') AS description_or_null\n",
      "FROM orders\n",
      "\n",
      "================================================================================\n",
      "FUNCTION MAPPINGS:\n",
      "================================================================================\n",
      "â€¢ IFF(condition, true_val, false_val) â†’ IF(condition, true_val, false_val)\n",
      "â€¢ NULLIF(value1, value2) â†’ NULLIF(value1, value2) (same)\n"
     ]
    }
   ],
   "source": [
    "# Example 9: Conditional logic\n",
    "snowflake_conditional = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    CASE \n",
    "        WHEN amount > 1000 THEN 'high'\n",
    "        WHEN amount > 100 THEN 'medium'\n",
    "        ELSE 'low'\n",
    "    END AS order_tier,\n",
    "    IFF(status = 'completed', amount, 0) AS completed_amount,\n",
    "    NULLIF(description, '') AS description_or_null\n",
    "FROM orders\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_conditional)\n",
    "\n",
    "bigquery_conditional = transpile(\n",
    "    snowflake_conditional,\n",
    "    read=Snowflake,\n",
    "    write=BigQuery,\n",
    "    pretty=True\n",
    ")[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BIGQUERY SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(bigquery_conditional)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FUNCTION MAPPINGS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"â€¢ IFF(condition, true_val, false_val) â†’ IF(condition, true_val, false_val)\")\n",
    "print(\"â€¢ NULLIF(value1, value2) â†’ NULLIF(value1, value2) (same)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Handling Identifier Quoting\n",
    "\n",
    "Snowflake and BigQuery handle identifier quoting differently. Snowflake uses double quotes by default, while BigQuery uses backticks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE SQL (using double quotes):\n",
      "================================================================================\n",
      "\n",
      "SELECT \n",
      "    \"User ID\" AS user_id,\n",
      "    \"First Name\" AS first_name,\n",
      "    \"Email Address\" AS email\n",
      "FROM \"Public\".\"Users\"\n",
      "WHERE \"Active Status\" = TRUE\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY SQL (using backticks):\n",
      "================================================================================\n",
      "SELECT\n",
      "  `User ID` AS user_id,\n",
      "  `First Name` AS first_name,\n",
      "  `Email Address` AS email\n",
      "FROM `Public`.`Users`\n",
      "WHERE\n",
      "  `Active Status` = TRUE\n",
      "\n",
      "================================================================================\n",
      "IDENTIFIER QUOTING:\n",
      "================================================================================\n",
      "â€¢ Snowflake: Uses double quotes (\"identifier\")\n",
      "â€¢ BigQuery: Uses backticks (`identifier`)\n",
      "â€¢ SQLGlot automatically converts between them\n"
     ]
    }
   ],
   "source": [
    "# Example 10: Identifier quoting\n",
    "snowflake_quoted = \"\"\"\n",
    "SELECT \n",
    "    \"User ID\" AS user_id,\n",
    "    \"First Name\" AS first_name,\n",
    "    \"Email Address\" AS email\n",
    "FROM \"Public\".\"Users\"\n",
    "WHERE \"Active Status\" = TRUE\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE SQL (using double quotes):\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_quoted)\n",
    "\n",
    "bigquery_quoted = transpile(\n",
    "    snowflake_quoted,\n",
    "    read=Snowflake,\n",
    "    write=BigQuery,\n",
    "    pretty=True\n",
    ")[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BIGQUERY SQL (using backticks):\")\n",
    "print(\"=\" * 80)\n",
    "print(bigquery_quoted)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"IDENTIFIER QUOTING:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"â€¢ Snowflake: Uses double quotes (\\\"identifier\\\")\")\n",
    "print(\"â€¢ BigQuery: Uses backticks (`identifier`)\")\n",
    "print(\"â€¢ SQLGlot automatically converts between them\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Complex Query: Combining Multiple Features\n",
    "\n",
    "Let's create a more complex query that combines multiple features to see how SQLGlot handles the full transpilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SNOWFLAKE SQL (Complex Query):\n",
      "================================================================================\n",
      "\n",
      "WITH monthly_sales AS (\n",
      "    SELECT \n",
      "        DATE_TRUNC('month', created_at) AS month,\n",
      "        user_id,\n",
      "        SUM(amount) AS total_amount,\n",
      "        COUNT(*) AS order_count\n",
      "    FROM orders\n",
      "    WHERE created_at >= DATEADD(month, -12, CURRENT_DATE())\n",
      "    GROUP BY 1, 2\n",
      "),\n",
      "user_rankings AS (\n",
      "    SELECT \n",
      "        month,\n",
      "        user_id,\n",
      "        total_amount,\n",
      "        ROW_NUMBER() OVER (PARTITION BY month ORDER BY total_amount DESC) AS user_rank,\n",
      "        SUM(total_amount) OVER (PARTITION BY month) AS monthly_total\n",
      "    FROM monthly_sales\n",
      ")\n",
      "SELECT \n",
      "    u.email,\n",
      "    ur.month,\n",
      "    ur.total_amount,\n",
      "    ur.user_rank,\n",
      "    ROUND(ur.total_amount / ur.monthly_total * 100, 2) || '%' AS pct_of_monthly\n",
      "FROM user_rankings ur\n",
      "INNER JOIN users u ON ur.user_id = u.id\n",
      "WHERE ur.user_rank <= 10\n",
      "ORDER BY ur.month DESC, ur.user_rank ASC\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BIGQUERY SQL (Transpiled):\n",
      "================================================================================\n",
      "WITH monthly_sales AS (\n",
      "  SELECT\n",
      "    TIMESTAMP_TRUNC(created_at, MONTH) AS month,\n",
      "    user_id,\n",
      "    SUM(amount) AS total_amount,\n",
      "    COUNT(*) AS order_count\n",
      "  FROM orders\n",
      "  WHERE\n",
      "    created_at >= DATE_ADD(CURRENT_DATE, INTERVAL -12 MONTH)\n",
      "  GROUP BY\n",
      "    1,\n",
      "    2\n",
      "), user_rankings AS (\n",
      "  SELECT\n",
      "    month,\n",
      "    user_id,\n",
      "    total_amount,\n",
      "    ROW_NUMBER() OVER (PARTITION BY month ORDER BY total_amount DESC NULLS FIRST) AS user_rank,\n",
      "    SUM(total_amount) OVER (PARTITION BY month) AS monthly_total\n",
      "  FROM monthly_sales\n",
      ")\n",
      "SELECT\n",
      "  u.email,\n",
      "  ur.month,\n",
      "  ur.total_amount,\n",
      "  ur.user_rank,\n",
      "  ROUND(ur.total_amount / ur.monthly_total * 100, 2) || '%' AS pct_of_monthly\n",
      "FROM user_rankings AS ur\n",
      "INNER JOIN users AS u\n",
      "  ON ur.user_id = u.id\n",
      "WHERE\n",
      "  ur.user_rank <= 10\n",
      "ORDER BY\n",
      "  ur.month DESC NULLS FIRST,\n",
      "  ur.user_rank ASC NULLS LAST\n"
     ]
    }
   ],
   "source": [
    "# Example 11: Complex query combining multiple features\n",
    "snowflake_complex = \"\"\"\n",
    "WITH monthly_sales AS (\n",
    "    SELECT \n",
    "        DATE_TRUNC('month', created_at) AS month,\n",
    "        user_id,\n",
    "        SUM(amount) AS total_amount,\n",
    "        COUNT(*) AS order_count\n",
    "    FROM orders\n",
    "    WHERE created_at >= DATEADD(month, -12, CURRENT_DATE())\n",
    "    GROUP BY 1, 2\n",
    "),\n",
    "user_rankings AS (\n",
    "    SELECT \n",
    "        month,\n",
    "        user_id,\n",
    "        total_amount,\n",
    "        ROW_NUMBER() OVER (PARTITION BY month ORDER BY total_amount DESC) AS user_rank,\n",
    "        SUM(total_amount) OVER (PARTITION BY month) AS monthly_total\n",
    "    FROM monthly_sales\n",
    ")\n",
    "SELECT \n",
    "    u.email,\n",
    "    ur.month,\n",
    "    ur.total_amount,\n",
    "    ur.user_rank,\n",
    "    ROUND(ur.total_amount / ur.monthly_total * 100, 2) || '%' AS pct_of_monthly\n",
    "FROM user_rankings ur\n",
    "INNER JOIN users u ON ur.user_id = u.id\n",
    "WHERE ur.user_rank <= 10\n",
    "ORDER BY ur.month DESC, ur.user_rank ASC\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SNOWFLAKE SQL (Complex Query):\")\n",
    "print(\"=\" * 80)\n",
    "print(snowflake_complex)\n",
    "\n",
    "bigquery_complex = transpile(\n",
    "    snowflake_complex,\n",
    "    read=Snowflake,\n",
    "    write=BigQuery,\n",
    "    pretty=True\n",
    ")[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BIGQUERY SQL (Transpiled):\")\n",
    "print(\"=\" * 80)\n",
    "print(bigquery_complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Parsing and AST Inspection\n",
    "\n",
    "SQLGlot can parse SQL into an Abstract Syntax Tree (AST), which allows for programmatic manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ORIGINAL SQL:\n",
      "================================================================================\n",
      "SELECT id, name FROM users WHERE active = TRUE LIMIT 100\n",
      "\n",
      "================================================================================\n",
      "AST STRUCTURE:\n",
      "================================================================================\n",
      "Root type: Select\n",
      "Number of expressions: 2\n",
      "\n",
      "================================================================================\n",
      "TABLE REFERENCES:\n",
      "================================================================================\n",
      "  â€¢ users\n",
      "\n",
      "================================================================================\n",
      "COLUMN REFERENCES:\n",
      "================================================================================\n",
      "  â€¢ id\n",
      "  â€¢ name\n",
      "  â€¢ active\n",
      "\n",
      "================================================================================\n",
      "WHERE CLAUSE FOUND:\n",
      "================================================================================\n",
      "  WHERE active = TRUE\n",
      "\n",
      "================================================================================\n",
      "RECONSTRUCTED SQL:\n",
      "================================================================================\n",
      "SELECT id, name FROM users WHERE active = TRUE LIMIT 100\n"
     ]
    }
   ],
   "source": [
    "# Example 12: Parsing and AST inspection\n",
    "sql = \"SELECT id, name FROM users WHERE active = TRUE LIMIT 100\"\n",
    "\n",
    "# Parse into AST\n",
    "ast = parse_one(sql, read=Snowflake)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ORIGINAL SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(sql)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AST STRUCTURE:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Root type: {type(ast).__name__}\")\n",
    "print(f\"Number of expressions: {len(ast.expressions)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TABLE REFERENCES:\")\n",
    "print(\"=\" * 80)\n",
    "tables = ast.find_all(exp.Table)\n",
    "for table in tables:\n",
    "    print(f\"  â€¢ {table}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COLUMN REFERENCES:\")\n",
    "print(\"=\" * 80)\n",
    "columns = ast.find_all(exp.Column)\n",
    "for col in columns:\n",
    "    print(f\"  â€¢ {col}\")\n",
    "\n",
    "# Modify the AST (e.g., add a condition)\n",
    "where_clause = ast.find(exp.Where)\n",
    "if where_clause:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"WHERE CLAUSE FOUND:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"  {where_clause}\")\n",
    "\n",
    "# Convert back to SQL\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECONSTRUCTED SQL:\")\n",
    "print(\"=\" * 80)\n",
    "print(ast.sql(dialect=Snowflake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Error Handling and Edge Cases\n",
    "\n",
    "Some SQL constructs might not translate perfectly. Let's examine how SQLGlot handles edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST CASE 1:\n",
      "================================================================================\n",
      "SELECT * FROM (\n",
      "        SELECT category, amount FROM sales\n",
      "    ) PIVOT (\n",
      "        SUM(amount) FOR category IN ('A', 'B', 'C')\n",
      "    ) AS p\n",
      "\n",
      "âœ… TRANSPILATION SUCCESS:\n",
      "SELECT\n",
      "  *\n",
      "FROM (\n",
      "  SELECT\n",
      "    category,\n",
      "    amount\n",
      "  FROM sales\n",
      ")\n",
      "PIVOT(SUM(amount) FOR category IN ('A', 'B', 'C')) AS p\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST CASE 2:\n",
      "================================================================================\n",
      "SELECT id, amount, ROW_NUMBER() OVER (ORDER BY amount DESC) AS rn\n",
      "    FROM orders\n",
      "    QUALIFY rn <= 10\n",
      "\n",
      "âœ… TRANSPILATION SUCCESS:\n",
      "SELECT\n",
      "  id,\n",
      "  amount,\n",
      "  ROW_NUMBER() OVER (ORDER BY amount DESC NULLS FIRST) AS rn\n",
      "FROM orders\n",
      "QUALIFY\n",
      "  rn <= 10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 13: Handling potential issues\n",
    "test_cases = [\n",
    "    # Test case 1: PIVOT operation (handled differently)\n",
    "    \"\"\"\n",
    "    SELECT * FROM (\n",
    "        SELECT category, amount FROM sales\n",
    "    ) PIVOT (\n",
    "        SUM(amount) FOR category IN ('A', 'B', 'C')\n",
    "    ) AS p\n",
    "    \"\"\",\n",
    "    \n",
    "    # Test case 2: QUALIFY clause (Snowflake-specific)\n",
    "    \"\"\"\n",
    "    SELECT id, amount, ROW_NUMBER() OVER (ORDER BY amount DESC) AS rn\n",
    "    FROM orders\n",
    "    QUALIFY rn <= 10\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "for i, test_sql in enumerate(test_cases, 1):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"TEST CASE {i}:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(test_sql.strip())\n",
    "    \n",
    "    try:\n",
    "        result = transpile(\n",
    "            test_sql,\n",
    "            read=Snowflake,\n",
    "            write=BigQuery,\n",
    "            pretty=True\n",
    "        )[0]\n",
    "        \n",
    "        print(\"\\nâœ… TRANSPILATION SUCCESS:\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸  TRANSPILATION FAILED:\")\n",
    "        print(f\"   Error: {e}\")\n",
    "        print(\"\\nðŸ’¡ MANUAL CONVERSION REQUIRED\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Key Differences Between Snowflake and BigQuery\n",
    "\n",
    "### âœ… Automatically Handled by SQLGlot\n",
    "\n",
    "1. **String Concatenation**: `||` â†’ `CONCAT()`\n",
    "2. **Date Functions**: `DATEADD()`, `DATEDIFF()` â†’ `DATE_ADD()`, `DATE_DIFF()`\n",
    "3. **Conditional Functions**: `IFF()` â†’ `IF()`\n",
    "4. **Identifier Quoting**: Double quotes â†’ Backticks\n",
    "5. **Data Types**: `NUMBER`, `VARCHAR`, `TEXT` â†’ `INT64`, `NUMERIC`, `STRING`\n",
    "6. **TIMESTAMP_NTZ**: â†’ `TIMESTAMP`\n",
    "\n",
    "### âš ï¸  May Require Manual Adjustment\n",
    "\n",
    "1. **Array Functions**: `ARRAY_SIZE()`, `ARRAY_CONTAINS()` â†’ Different syntax in BigQuery\n",
    "2. **JSON Functions**: `OBJECT_KEYS()`, `GET()` â†’ Use `JSON_EXTRACT_SCALAR()` in BigQuery\n",
    "3. **PIVOT Operations**: Different syntax between dialects\n",
    "4. **QUALIFY Clause**: Snowflake-specific, needs rewriting in BigQuery\n",
    "5. **VARIANT Type**: May need explicit JSON handling in BigQuery\n",
    "\n",
    "### ðŸ’¡ Best Practices\n",
    "\n",
    "1. **Always Review**: Transpiled SQL should be reviewed before execution\n",
    "2. **Test Queries**: Test on sample data when possible\n",
    "3. **Check Functions**: Verify that all functions are correctly mapped\n",
    "4. **Handle Edge Cases**: Some Snowflake-specific features may need manual conversion\n",
    "5. **Use AST Inspection**: For complex transformations, inspect and modify the AST programmatically\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **SQLGlot Documentation**: https://github.com/tobymao/sqlglot\n",
    "- **Snowflake SQL Reference**: https://docs.snowflake.com/en/sql-reference/\n",
    "- **BigQuery SQL Reference**: https://cloud.google.com/bigquery/docs/reference/standard-sql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
